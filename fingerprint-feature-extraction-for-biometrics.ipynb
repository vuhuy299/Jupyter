{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fingerprint Feature Extraction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction:\n",
    "\n",
    "Fingerprint biometrics involve: Image Acquisition, Image Enhancing, Feature extraction and matching with template. Since the dataset has unique fingerprints I will implement feature extraction and different techniques for enhancing images such as Edge detection, adaptive thresholding. Feature extraction constitutes of Ridge detection (level 1 feature) and Minutiae extraction (level 3 feature) to generate a template after whicha query image is matched using the metric ROC AUC curve.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-04-06T06:59:25.027425Z",
     "iopub.status.busy": "2022-04-06T06:59:25.026988Z",
     "iopub.status.idle": "2022-04-06T06:59:26.928502Z",
     "shell.execute_reply": "2022-04-06T06:59:26.927108Z",
     "shell.execute_reply.started": "2022-04-06T06:59:25.027385Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import random\n",
    "import imageio\n",
    "import PIL, cv2\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.morphology import convex_hull_image, erosion\n",
    "from skimage.morphology import square\n",
    "import matplotlib.image as mpimg\n",
    "import skimage\n",
    "import math\n",
    "from scipy.ndimage import convolve\n",
    "from PIL import Image,ImageFilter\n",
    "from skimage.feature import hessian_matrix, hessian_matrix_eigvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-06T06:59:26.931615Z",
     "iopub.status.busy": "2022-04-06T06:59:26.931158Z",
     "iopub.status.idle": "2022-04-06T06:59:27.496210Z",
     "shell.execute_reply": "2022-04-06T06:59:27.495088Z",
     "shell.execute_reply.started": "2022-04-06T06:59:26.931569Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000\n"
     ]
    }
   ],
   "source": [
    "# KAGGLE FINGERPRINT DATA\n",
    "\n",
    "list_dirs = list(glob.glob(\"F:/CODE/Python/Jupyter/Data/Real/*.bmp\"))\n",
    "num_images = len(list_dirs)\n",
    "print(len(list_dirs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Displaying random images from data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-06T06:59:27.500787Z",
     "iopub.status.busy": "2022-04-06T06:59:27.500404Z",
     "iopub.status.idle": "2022-04-06T06:59:28.179948Z",
     "shell.execute_reply": "2022-04-06T06:59:28.179114Z",
     "shell.execute_reply.started": "2022-04-06T06:59:27.500749Z"
    }
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m display_list \u001b[38;5;241m=\u001b[39m list_dirs[r:r\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m3\u001b[39m]\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# image1 = imageio.imread(display_list[0])\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m image2 \u001b[38;5;241m=\u001b[39m imageio\u001b[38;5;241m.\u001b[39mimread(\u001b[43mdisplay_list\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[0;32m      8\u001b[0m image3 \u001b[38;5;241m=\u001b[39m imageio\u001b[38;5;241m.\u001b[39mimread(display_list[\u001b[38;5;241m2\u001b[39m])\n\u001b[0;32m     10\u001b[0m fig, axes \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m3\u001b[39m,figsize \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m16\u001b[39m,\u001b[38;5;241m16\u001b[39m));\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# random.seed(42)\n",
    "\n",
    "r = 1\n",
    "display_list = list_dirs[r:r+3]\n",
    "\n",
    "image1 = imageio.imread(display_list[0])\n",
    "image2 = imageio.imread(display_list[1])\n",
    "image3 = imageio.imread(display_list[2])\n",
    "\n",
    "fig, axes = plt.subplots(1,3,figsize = (16,16));\n",
    "axes[0].imshow(image1);\n",
    "axes[1].imshow(image2);\n",
    "axes[2].imshow(image3);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Transforms\n",
    "\n",
    "1. Image Smoothening\n",
    "2. Thresholding\n",
    "3. Edge Detection\n",
    "\n",
    "Image enhancement and preprocessing techniques such as smoothing, thresholding and edge detection are used to make features more prominent in data for extraction to be more accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-06T07:25:04.221478Z",
     "iopub.status.busy": "2022-04-06T07:25:04.221082Z",
     "iopub.status.idle": "2022-04-06T07:25:05.131622Z",
     "shell.execute_reply": "2022-04-06T07:25:05.130427Z",
     "shell.execute_reply.started": "2022-04-06T07:25:04.221446Z"
    }
   },
   "outputs": [],
   "source": [
    "gauss_blur = cv2.GaussianBlur(image1,(1,1),0)\n",
    "median_blur = cv2.medianBlur(image1,1)\n",
    "\n",
    "gauss_blur2 = cv2.GaussianBlur(image2,(1,1),0)\n",
    "median_blur2 = cv2.medianBlur(image2,1)\n",
    "\n",
    "fig, axes = plt.subplots(1,3,figsize = (16,16));\n",
    "axes[0].set_title(\"original Image\");\n",
    "axes[0].imshow(image1);\n",
    "axes[1].set_title(\"Gaussian Blurred Image\");\n",
    "axes[1].imshow(gauss_blur);\n",
    "axes[2].set_title(\"Median Blurred Image\");\n",
    "axes[2].imshow(median_blur);\n",
    "fig, axes = plt.subplots(1,3,figsize = (16,16));\n",
    "axes[0].set_title(\"original Image 2\");\n",
    "axes[0].imshow(image2);\n",
    "axes[1].set_title(\"Gaussian Blurred Image 2\");\n",
    "axes[1].imshow(gauss_blur2);\n",
    "axes[2].set_title(\"Median Blurred Image 2\");\n",
    "axes[2].imshow(median_blur2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-06T06:59:28.646895Z",
     "iopub.status.busy": "2022-04-06T06:59:28.646561Z",
     "iopub.status.idle": "2022-04-06T06:59:30.564542Z",
     "shell.execute_reply": "2022-04-06T06:59:30.563524Z",
     "shell.execute_reply.started": "2022-04-06T06:59:28.646864Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,3,figsize = (18,5))\n",
    "axes[0].hist(image1.ravel(), bins=256, color =\"r\");\n",
    "axes[1].hist(image2.ravel(), bins=256);\n",
    "axes[2].hist(image3.ravel(), bins=256, color =\"g\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data seems to be almost binary - implementing mean and adaptive thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-06T06:59:30.567319Z",
     "iopub.status.busy": "2022-04-06T06:59:30.566895Z",
     "iopub.status.idle": "2022-04-06T06:59:31.012120Z",
     "shell.execute_reply": "2022-04-06T06:59:31.010973Z",
     "shell.execute_reply.started": "2022-04-06T06:59:30.567274Z"
    }
   },
   "outputs": [],
   "source": [
    "# mean thresholding - gives bad results\n",
    "THRESHOLD1 = image1.mean()\n",
    "THRESHOLD2 = image2.mean()\n",
    "THRESHOLD3 = image3.mean()\n",
    "\n",
    "image1 = np.array(image1 > THRESHOLD1).astype(int) * 255\n",
    "image2 = np.array(image2 > THRESHOLD2).astype(int) * 254\n",
    "image3 = np.array(image3 > THRESHOLD3).astype(int) * 254\n",
    "\n",
    "fig, axes = plt.subplots(1,3,figsize = (16,16));\n",
    "axes[0].imshow(image1);\n",
    "axes[1].imshow(image2);\n",
    "axes[2].imshow(image3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-06T06:59:31.014281Z",
     "iopub.status.busy": "2022-04-06T06:59:31.013863Z",
     "iopub.status.idle": "2022-04-06T06:59:31.436742Z",
     "shell.execute_reply": "2022-04-06T06:59:31.435802Z",
     "shell.execute_reply.started": "2022-04-06T06:59:31.014238Z"
    }
   },
   "outputs": [],
   "source": [
    "# Adaptive thresholding from OpenCV library - better than Mean Thresholding\n",
    "\n",
    "img1 = cv2.imread(display_list[0],0)\n",
    "img2 = cv2.imread(display_list[1],0)\n",
    "img3 = cv2.imread(display_list[2],0)\n",
    "\n",
    "# Otsu's thresholding\n",
    "ret1,th1 = cv2.threshold(img1,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "ret2,th2 = cv2.threshold(img2,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "ret3,th3 = cv2.threshold(img3,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "\n",
    "fig, axes = plt.subplots(1,3,figsize = (12,12));\n",
    "axes[0].set_title(\"Otsu's thresholding - Image 1\");\n",
    "axes[0].imshow(th2);\n",
    "axes[1].set_title(\"Otsu's thresholding - Image 2\");\n",
    "axes[1].imshow(th2);\n",
    "axes[2].set_title(\"Otsu's thresholding - Image 3\");\n",
    "axes[2].imshow(th2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edge detection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-06T06:59:31.438304Z",
     "iopub.status.busy": "2022-04-06T06:59:31.437998Z",
     "iopub.status.idle": "2022-04-06T06:59:31.447088Z",
     "shell.execute_reply": "2022-04-06T06:59:31.445995Z",
     "shell.execute_reply.started": "2022-04-06T06:59:31.438273Z"
    }
   },
   "outputs": [],
   "source": [
    "# convert to grayscale\n",
    "img_name = display_list[0]\n",
    "gray_img_array = np.array(Image.open(img_name).convert('P'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Robert, Sobel, Prewitt Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-06T06:59:31.449407Z",
     "iopub.status.busy": "2022-04-06T06:59:31.448905Z",
     "iopub.status.idle": "2022-04-06T06:59:31.463873Z",
     "shell.execute_reply": "2022-04-06T06:59:31.462966Z",
     "shell.execute_reply.started": "2022-04-06T06:59:31.449359Z"
    }
   },
   "outputs": [],
   "source": [
    "vertical_robert_filter = np.array([[1,0],[0,-1]])\n",
    "horizontal_robert_filter = np.array([[0,1],[-1,0]])\n",
    "\n",
    "vertical_sobel_filter = np.array([[-1,0,1],[-2,0,2],[-1,0,1]])\n",
    "horizontal_sobel_filter = np.array([[-1,-2,-1],[0,0,0],[1,2,1]])\n",
    "\n",
    "vertical_prewitt_filter = np.array([[-1,0,1],[-1,0,1],[-1,0,1]])\n",
    "horizontal_prewitt_filter = np.array([[-1,-1,-1],[0,0,0],[1,1,1]])\n",
    "\n",
    "print(\"vertical robert filter\\n\",vertical_robert_filter )\n",
    "print(\"horizontal robert filter\\n\",horizontal_robert_filter)\n",
    "print(\"vertical sobel filter: \\n\", vertical_sobel_filter)\n",
    "print(\"horizontal sobel filter: \\n\", horizontal_sobel_filter)\n",
    "\n",
    "print(\"vertical prewitt filter: \\n\", vertical_prewitt_filter)\n",
    "print(\"horizontal prewitt filter: \\n\", horizontal_prewitt_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-06T06:59:31.465503Z",
     "iopub.status.busy": "2022-04-06T06:59:31.465159Z",
     "iopub.status.idle": "2022-04-06T06:59:31.478583Z",
     "shell.execute_reply": "2022-04-06T06:59:31.477603Z",
     "shell.execute_reply.started": "2022-04-06T06:59:31.465472Z"
    }
   },
   "outputs": [],
   "source": [
    "# implementing:\n",
    "gray_img = Image.fromarray(gray_img_array)\n",
    "\n",
    "convolved_img1 = convolve(gray_img,vertical_robert_filter)\n",
    "convolved_img1 = convolve(convolved_img1,horizontal_robert_filter)\n",
    "\n",
    "convolved_img2 = convolve(gray_img,vertical_sobel_filter)\n",
    "convolved_img2 = convolve(convolved_img2,horizontal_sobel_filter)\n",
    "\n",
    "convolved_img3 =  convolve(gray_img,vertical_prewitt_filter )\n",
    "convolved_img3 =  convolve(gray_img,horizontal_prewitt_filter )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-06T06:59:31.480424Z",
     "iopub.status.busy": "2022-04-06T06:59:31.479912Z",
     "iopub.status.idle": "2022-04-06T06:59:31.943005Z",
     "shell.execute_reply": "2022-04-06T06:59:31.942166Z",
     "shell.execute_reply.started": "2022-04-06T06:59:31.480381Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,3,figsize = (12,12));\n",
    "axes[0].set_title(\"Robert\");\n",
    "axes[0].imshow(convolved_img1);\n",
    "axes[1].set_title(\"Sobel\");\n",
    "axes[1].imshow(convolved_img2);\n",
    "axes[2].set_title(\"Prewitt\");\n",
    "axes[2].imshow(convolved_img3);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-06T06:59:31.944655Z",
     "iopub.status.busy": "2022-04-06T06:59:31.944187Z",
     "iopub.status.idle": "2022-04-06T06:59:32.172436Z",
     "shell.execute_reply": "2022-04-06T06:59:32.171075Z",
     "shell.execute_reply.started": "2022-04-06T06:59:31.944611Z"
    }
   },
   "outputs": [],
   "source": [
    "src_path = img_name\n",
    "\n",
    "def detect_ridges(gray, sigma= 0.1):\n",
    "    H_elems = hessian_matrix(gray, sigma=sigma, order='rc')\n",
    "    maxima_ridges, minima_ridges = hessian_matrix_eigvals(H_elems)\n",
    "    return maxima_ridges, minima_ridges\n",
    "\n",
    "def plot_images(*images):\n",
    "    images = list(images)\n",
    "    n = len(images)\n",
    "    fig, ax = plt.subplots(ncols=n, sharey=True, figsize = (12,12))\n",
    "    for i, img in enumerate(images):\n",
    "        ax[i].imshow(img, cmap='gray')\n",
    "        ax[i].axis('off')\n",
    "    plt.subplots_adjust(left=0.03, bottom=0.03, right=0.97, top=0.97)\n",
    "    plt.show()\n",
    "\n",
    "img = cv2.imread(src_path, 0) # 0 imports a grayscale\n",
    "if img is None:\n",
    "    raise(ValueError(f\"Image didn\\'t load. Check that '{src_path}' exists.\"))\n",
    "\n",
    "a, b = detect_ridges(img, sigma=0.15)\n",
    "\n",
    "plot_images(img, a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Termination and Bifurcation detection and Minutiae Extraction\n",
    "\n",
    "The given code extracts features like Termination, Bifurcation and Minutiae from finger prints, the output is shown below the code:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-06T06:59:32.174485Z",
     "iopub.status.busy": "2022-04-06T06:59:32.174073Z",
     "iopub.status.idle": "2022-04-06T06:59:32.187519Z",
     "shell.execute_reply": "2022-04-06T06:59:32.185658Z",
     "shell.execute_reply.started": "2022-04-06T06:59:32.174445Z"
    }
   },
   "outputs": [],
   "source": [
    "def getTerminationBifurcation(img, mask):\n",
    "    img = img == 255;\n",
    "    (rows, cols) = img.shape;\n",
    "    minutiaeTerm = np.zeros(img.shape);\n",
    "    minutiaeBif = np.zeros(img.shape);\n",
    "    \n",
    "    for i in range(1,rows-1):\n",
    "        for j in range(1,cols-1):\n",
    "            if(img[i][j] == 1):\n",
    "                block = img[i-1:i+2,j-1:j+2];\n",
    "                block_val = np.sum(block);\n",
    "                if(block_val == 2):\n",
    "                    minutiaeTerm[i,j] = 1;\n",
    "                elif(block_val == 4):\n",
    "                    minutiaeBif[i,j] = 1;\n",
    "    \n",
    "    mask = convex_hull_image(mask>0)\n",
    "    mask = erosion(mask, square(5))         \n",
    "    minutiaeTerm = np.uint8(mask)*minutiaeTerm\n",
    "    return(minutiaeTerm, minutiaeBif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-06T07:30:14.079303Z",
     "iopub.status.busy": "2022-04-06T07:30:14.078858Z",
     "iopub.status.idle": "2022-04-06T07:30:14.117901Z",
     "shell.execute_reply": "2022-04-06T07:30:14.116945Z",
     "shell.execute_reply.started": "2022-04-06T07:30:14.079267Z"
    }
   },
   "outputs": [],
   "source": [
    "class MinutiaeFeature(object):\n",
    "    def __init__(self, locX, locY, Orientation, Type):\n",
    "        self.locX = locX;\n",
    "        self.locY = locY;\n",
    "        self.Orientation = Orientation;\n",
    "        self.Type = Type;\n",
    "    \n",
    "    def __str__(self):\n",
    "        return(\"%d %d %f %s\" % (self.locX, self.locY, self.Orientation, self.Type))\n",
    "\n",
    "def computeAngle(block, minutiaeType):\n",
    "    angle = 0\n",
    "    (blkRows, blkCols) = np.shape(block);\n",
    "    CenterX, CenterY = (blkRows-1)/2, (blkCols-1)/2\n",
    "    if(minutiaeType.lower() == 'termination'):\n",
    "        sumVal = 0;\n",
    "        for i in range(blkRows):\n",
    "            for j in range(blkCols):\n",
    "                if((i == 0 or i == blkRows-1 or j == 0 or j == blkCols-1) and block[i][j] != 0):\n",
    "                    angle = -math.degrees(math.atan2(i-CenterY, j-CenterX))\n",
    "                    sumVal += 1\n",
    "                    if(sumVal > 1):\n",
    "                        angle = float('nan');\n",
    "        return(angle)\n",
    "    elif(minutiaeType.lower() == 'bifurcation'):\n",
    "        (blkRows, blkCols) = np.shape(block);\n",
    "        CenterX, CenterY = (blkRows - 1) / 2, (blkCols - 1) / 2\n",
    "        angle = []\n",
    "        sumVal = 0;\n",
    "        for i in range(blkRows):\n",
    "            for j in range(blkCols):\n",
    "                if ((i == 0 or i == blkRows - 1 or j == 0 or j == blkCols - 1) and block[i][j] != 0):\n",
    "                    angle.append(-math.degrees(math.atan2(i - CenterY, j - CenterX)))\n",
    "                    sumVal += 1\n",
    "        if(sumVal != 3):\n",
    "            angle = float('nan')\n",
    "        return(angle)\n",
    "\n",
    "\n",
    "def extractMinutiaeFeatures(skel, minutiaeTerm, minutiaeBif):\n",
    "    FeaturesTerm = []\n",
    "\n",
    "    minutiaeTerm = skimage.measure.label(minutiaeTerm, connectivity=2);\n",
    "    RP = skimage.measure.regionprops(minutiaeTerm)\n",
    "    \n",
    "    WindowSize = 2          \n",
    "    FeaturesTerm = []\n",
    "    for i in RP:\n",
    "        (row, col) = np.int16(np.round(i['Centroid']))\n",
    "        block = skel[row-WindowSize:row+WindowSize+1, col-WindowSize:col+WindowSize+1]\n",
    "        angle = computeAngle(block, 'Termination')\n",
    "        FeaturesTerm.append(MinutiaeFeature(row, col, angle, 'Termination'))\n",
    "\n",
    "    FeaturesBif = []\n",
    "    minutiaeBif = skimage.measure.label(minutiaeBif, connectivity=2);\n",
    "    RP = skimage.measure.regionprops(minutiaeBif)\n",
    "    WindowSize = 1 \n",
    "    for i in RP:\n",
    "        (row, col) = np.int16(np.round(i['Centroid']))\n",
    "        block = skel[row-WindowSize:row+WindowSize+1, col-WindowSize:col+WindowSize+1]\n",
    "        angle = computeAngle(block, 'Bifurcation')\n",
    "        FeaturesBif.append(MinutiaeFeature(row, col, angle, 'Bifurcation'))\n",
    "    return(FeaturesTerm, FeaturesBif)\n",
    "\n",
    "    \n",
    "def ShowResults(skel, TermLabel, BifLabel):\n",
    "    minutiaeBif = TermLabel * 0;\n",
    "    minutiaeTerm = BifLabel * 0;\n",
    "    (rows, cols) = skel.shape\n",
    "    DispImg = np.zeros((rows, cols, 3), np.uint8)\n",
    "    DispImg[:, :, 0] = skel;\n",
    "    DispImg[:, :, 1] = skel;\n",
    "    DispImg[:, :, 2] = skel;\n",
    "\n",
    "    RP = skimage.measure.regionprops(BifLabel)\n",
    "    bifCoord = []\n",
    "    termCoord = []\n",
    "    for idx, i in enumerate(RP):\n",
    "        (row, col) = np.int16(np.round(i['Centroid']))\n",
    "        minutiaeBif[row, col] = 1;\n",
    "        (rr, cc) = skimage.draw.circle_perimeter(row, col, 1);\n",
    "        skimage.draw.set_color(DispImg, (rr, cc), (255, 0, 0));\n",
    "        #bifCoord.append(\"x = %d , y = %d, %s\" %(row, col, 'B'))\n",
    "\n",
    "    RP = skimage.measure.regionprops(TermLabel)\n",
    "    for idx, i in enumerate(RP):\n",
    "        (row, col) = np.int16(np.round(i['Centroid']))\n",
    "        minutiaeTerm[row, col] = 1;\n",
    "        (rr, cc) = skimage.draw.circle_perimeter(row, col, 1);\n",
    "        skimage.draw.set_color(DispImg, (rr, cc), (0, 0, 255));\n",
    "        print(\" x = %d , y = %d %s\" % (row, col, 'T'))\n",
    "        \n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.title(\"Minutiae extraction results\")\n",
    "    plt.imshow(DispImg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-06T08:00:45.350842Z",
     "iopub.status.busy": "2022-04-06T08:00:45.350368Z",
     "iopub.status.idle": "2022-04-06T08:00:45.652304Z",
     "shell.execute_reply": "2022-04-06T08:00:45.651330Z",
     "shell.execute_reply.started": "2022-04-06T08:00:45.350801Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "img_name = display_list[1]\n",
    "img = cv2.imread(img_name,0);\n",
    "img = np.array(img > THRESHOLD1).astype(int)\n",
    "skel = skimage.morphology.skeletonize(img)\n",
    "skel = np.uint8(skel)*255;\n",
    "mask = img*255;\n",
    "\n",
    "(minutiaeTerm, minutiaeBif) = getTerminationBifurcation(skel, mask);\n",
    "FeaturesTerm, FeaturesBif = extractMinutiaeFeatures(skel, minutiaeTerm, minutiaeBif)\n",
    "# for t in FeaturesTerm:\n",
    "#     print(str(t))\n",
    "# for b in FeaturesBif:\n",
    "#     print(str(b))\n",
    "#print(FeaturesTerm)\n",
    "#print(FeaturesBif)\n",
    "print(\"--------\")\n",
    "BifLabel = skimage.measure.label(minutiaeBif, connectivity=1);\n",
    "TermLabel = skimage.measure.label(minutiaeTerm, connectivity=1);\n",
    "ShowResults(skel, TermLabel, BifLabel)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
